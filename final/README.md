# 架构设计大作业

## 背景

通达是一款本地即时配送平台。公司秉承“通派无障，使命必达”的信念，专注于用移动和众包的方式解决 O2O 领域最大的痛点：居民的最后 5 公里配送。

公司刚成立，已组建了 20 人的技术部门，准备两个月后系统开发完成上线。第一季目标日订单 1 万。

## 功能概述

- 用户通过 app 发起快递下单请求并支付
- 快递员通过自己的 APP 上报自己的物理地位，每 30 秒上报一次
- 系统收到快递请求后，向距离用户直线距离 5km 内的所有快递员发送通知
- 快递员需要进行抢单，第一个抢单的快递员得到配单，系统向其发送用户详细地址
- 快递员用户处收到快递，并记录到系统中：已收件
- 快递员将快递送到目的地，并记录到系统中：已送达

![用例图][1]

## 非功能性需求

系统预计上线三个月，日订单超过 1 万；一年后，日单超过 50 万

- 查询性能：平均响应时间 < 500ms, 95%响应时间 < 800ms
- 下单性能：平均响应时间 < 800ms, 95%响应时间 < 1000s
- 系统核心功能可用性： > 99.9%
- 系统安全性目标：可拦截 XSS 攻击，SQL 注入，CSRF 攻击，密码数据散列加密，客户端数据 HTTPS 加密，外部系统间通信加密。

## 系统部署图与整体设计

由于系统上线时间紧，而现阶段运维成本又较高；系统将直接搭建在阿里云服务上；集成云厂商提供的 DNS、CDN、Load Balance、API GateWay、Redis、Object Storage，MQ，以及 MySql 服务；用户 Auth 服务通过微信授权登陆。

![部署图][4]

如上有色区域所示，系统将分为三个子系统：读服务（Read API）、写服务（Write API）、推送服务（Notification Service）：

- Read API：主要用途是通过搜索 Redis，返回快递员实时位置信息

- Write API：

  - 首版本主要用于订单状态更新，以及定时更新快递员实时位置。
  - 上线三个月后，将该服务拆分为订单服务、支付服务、位置服务等等微服务集群

- Notification Service：顾名思义，与客户端保持长连接的服务。下单开始后，给快递员推送抢单；并推送用户订单进度。Write API 通过消息队列调用该服务。

## 订单服务活动图

![活动图][2]

该场景的主要流程如下：

1. 寄件人下单并支付
2. 系统向附近 5km 内的快递员发起抢单
3. 快递员抢单
4. 抢单成功后，系统给寄件人发送寄件码；快递员收到订单详细信息，并上门取件
5. 快递员上门取件后，输入取件码，开始派件；系统给收件人发送收件码
6. 快递员派送成功，输入收件码
7. 订单完成

## 下单抢单时序图

### 下单前

下单前，用户主动获取周边快递员信息，系统更新 Redis 缓存：

![用户][5]

### 下单时

下单过程如下所示：

![订单时序图][7]

1. 用户提交订单，服务器创建订单
2. 用户完成支付，通知服务器开始抢单
3. 推送服务向附近 5 公里以内的快递员广播抢单（快递员抢单见下图）
4. 抢单成功，用户收到寄件码

### 快递员抢单过程

快递员的抢单流程如下所示：

![骑手][6]

1. 抢单前，快递员实时更新坐标（30s）
2. 收到抢单通知后，立即抢单
3. 抢单成功后，系统返回订单详情
4. MQ 让推送服务给用户发送寄件码

## 订单状态图

![状态图][3]

## 三个月后系统升级

第一版的计划是尽快上线，因此只是设计的移动端的部署图。三个月后，若业务稳定，系统需要进一步升级，实现日订单 50 万的目标。改造计划如下：

1. 同时上线 PC 端和移动端；并增加BFF层，解耦前后端设计

2. 后台系统由先前简单的读写分离模式，改造为微服务的应用集群，包括用户服务、订单服务、推送服务、支付服务等等

3. 订单结束后，设计基于 MySql 到 MongoDB 的冷热分离

4. 建立后台系统的大数据分析平台

![升级计划][8]

[1]: ./img/use-case.drawio.png
[2]: ./img/pool.drawio.png
[3]: ./img/state.drawio.png
[4]: ./img/deploy.drawio.png
[5]: ./img/user.drawio.png
[6]: ./img/driver.drawio.png
[7]: ./img/order.drawio.png
[8]: ./img/next.drawio.png
